# CS260 Final Project Presentation
## Trained vs. Zero-Shot: Custom CNN vs. GPT-4o Vision on CIFAR-10

---

# ğŸ¯ SLIDE 1: Title Slide

## **Can a Custom CNN Compete with GPT-4o Vision?**

### Trained vs. Zero-Shot Image Classification on CIFAR-10

**CS260 Final Project**

*[Your Names Here]*

*December 2025*

---

# ğŸ¤” SLIDE 2: The Motivational Question

## The Rise of Giant AI Models

- OpenAI's GPT-4o: **~1.8 trillion parameters**
- Trained on **billions** of images from the internet
- Zero-shot capability: No training needed for new tasks

## Our Question:

> **Can a small, custom-trained CNN compete with these massive pre-trained models on image classification?**

ğŸ¯ If you train a model specifically for a task, can it match or beat a general-purpose giant?

---

# ğŸ–¼ï¸ SLIDE 3: The Dataset - CIFAR-10

## What is CIFAR-10?

| Property | Value |
|----------|-------|
| Total images | 60,000 |
| Training set | 50,000 |
| Test set | 10,000 |
| Image size | **32Ã—32 pixels** (tiny!) |
| Classes | 10 |

## The 10 Classes:

```
âœˆï¸ airplane   ğŸš— automobile   ğŸ¦ bird     ğŸ± cat      ğŸ¦Œ deer
ğŸ• dog        ğŸ¸ frog         ğŸ´ horse    ğŸš¢ ship     ğŸš› truck
```

**Challenge:** These images are TINY - hard even for humans to classify!

*[Include sample CIFAR-10 image grid]*

---

# ğŸ“Š SLIDE 4: Our Test Methodology

## Stratified Sampling: Fair Comparison

### The Problem:
- CIFAR-10 test set has **10,000 images** (1,000 per class)
- Testing all 10K with GPT-4o API would be expensive
- Need a **smaller but representative** subset

### Our Solution: Stratified Random Sampling

**Process:**
1. Group all 10,000 test images by their class label (0-9)
2. From each class, randomly select **200 indices** using `np.random.choice()`
3. Use **seed=42** for reproducibility (anyone can recreate exact same subset)
4. Store selected indices in `stratified_subset_2000.json`

| Parameter | Value |
|-----------|-------|
| Original test set | 10,000 images |
| Our subset | **2,000 images** |
| Per class | **200 images** (exactly) |
| Selection | Random without replacement |
| Seed | 42 (reproducible) |

### Technical Implementation:
```python
# For each class (0-9):
indices = np.random.choice(
    class_indices[class_id],  # All images of this class
    size=200,                  # Select exactly 200
    replace=False              # No duplicates
)
# Save to stratified_subset_2000.json
```

## Why This Matters:
- âœ… Both CNN and GPT-4o tested on **identical** 2,000 images
- âœ… Perfect class balance (no bias from unequal representation)
- âœ… Reproducible: Same seed â†’ same indices every time
- âœ… Affordable API cost (~$3 for 2,000 vs ~$15 for full 10K)
- âœ… Statistically significant (200 samples per class)

*[Show subset_distribution.png visualization]*

---

# ğŸ”§ SLIDE 5: Method 1 - Baseline CNN (Friend Presents)

## Our First CNN: Simple 2-Layer Architecture

```
Input: 32Ã—32Ã—3 (RGB)
    â†“
Conv2d(3 â†’ 32) + BatchNorm + ReLU + MaxPool (32Ã—32 â†’ 16Ã—16)
    â†“
Conv2d(32 â†’ 64) + BatchNorm + ReLU + MaxPool (16Ã—16 â†’ 8Ã—8)
    â†“
Flatten â†’ Linear(4096 â†’ 128) â†’ Dropout(0.5) â†’ Linear(128 â†’ 10)
    â†“
Output: 10 class probabilities
```

| Specs | Value |
|-------|-------|
| Convolutional layers | 2 |
| Parameters | ~1.2 million |
| Training data | 50,000 images |
| Training time | ~26 minutes |

---

# ğŸ“‰ SLIDE 6: Baseline CNN Results

## Accuracy: **71.55%**

| Metric | Value |
|--------|-------|
| Overall accuracy | 71.55% |
| Best class | automobile (86.5%) |
| Worst class | cat (42.5%) |

## Per-Class Performance:

| Strong Classes | Weak Classes |
|----------------|--------------|
| ğŸš— automobile: 86.5% | ğŸ± cat: 42.5% |
| ğŸš› truck: 83.0% | ğŸ¦ bird: 54.5% |
| ğŸ´ horse: 81.5% | ğŸ¦Œ deer: 60.0% |

**Problem:** Cat-Dog confusion is terrible! 56 cats predicted as dogs ğŸ˜¿

*[Show baseline confusion matrix]*

---

# ğŸ¤– SLIDE 7: Method 2 - GPT-4o Vision API (You Present)

## Zero-Shot Classification with GPT-4o

**No training required!** Just send image + prompt:

```python
Prompt: "Classify this image as exactly one of: 
         airplane, automobile, bird, cat, deer, 
         dog, frog, horse, ship, truck. 
         Return only the label."
```

## Technical Pipeline:

```
CIFAR-10 Image (32Ã—32) 
    â†’ Convert to PNG bytes 
    â†’ Base64 encode 
    â†’ Send to OpenAI API 
    â†’ Parse response
```

| Specs | Value |
|-------|-------|
| Model | GPT-4o Vision |
| Parameters | ~1.8 **trillion** |
| Training on CIFAR-10 | **None** (zero-shot) |
| Cost | ~$0.0008 per image (~$3 total for 4,000 calls!) |

---

# âš¡ SLIDE 8: GPT-4o Results

## Accuracy: **96.75%**

| Metric | Value |
|--------|-------|
| Correct predictions | 1,935 / 2,000 |
| Overall accuracy | **96.75%** |
| Best class | ship (99%) |
| Worst class | cat (94%) |

## Per-Class Performance:

| Class | Accuracy | Class | Accuracy |
|-------|----------|-------|----------|
| âœˆï¸ airplane | 97.5% | ğŸ• dog | 93.5% |
| ğŸš— automobile | 97.5% | ğŸ¸ frog | 93.5% |
| ğŸ¦ bird | 95.0% | ğŸ´ horse | 98.0% |
| ğŸ± cat | 94.0% | ğŸš¢ ship | **99.0%** |
| ğŸ¦Œ deer | 96.5% | ğŸš› truck | 98.5% |

*[Show GPT-4o confusion matrix]*

---

# ğŸ’¸ SLIDE 9: Fun Fact - The API Adventure

## Behind the Scenes of GPT-4o Testing

### The Numbers:
| Stat | Value |
|------|-------|
| API calls made | **4,000** (2,000 Ã— 2 experiments) |
| Total tokens | **1,196,000** |
| Total cost | **$3.04** â˜• (less than a coffee!) |
| Cost per image | **$0.00076** (~0.08 cents) |
| Time spent | ~80 minutes waiting |

### Why So Cheap?
- 32Ã—32 images = very few tokens
- Short responses (just "cat", "dog", etc.)
- GPT-4o pricing: $2.50/1M input tokens

### Why 4,000 calls?

We tested both:
1. **224Ã—224 upscaled images** (industry standard)
2. **32Ã—32 raw images** (original resolution)

**Surprising finding:** Both achieved **96.75%** - upscaling didn't help!

---

# ğŸ˜± SLIDE 10: The Gap Problem

## Houston, We Have a Problem!

| Model | Accuracy | Gap |
|-------|----------|-----|
| Baseline CNN | 71.55% | â€” |
| GPT-4o Vision | 96.75% | â€” |
| **Gap** | â€” | **25.2%** ğŸ˜¬ |

## The Challenge:

> GPT-4o has **1.8 trillion parameters** vs our CNN's **1.2 million**
> 
> That's **1,500,000Ã— more parameters!**

### But we didn't give up...

> *"What if we improve our CNN? Can we close the gap?"*

---

# ğŸ”¨ SLIDE 11: CNN Improvement Strategy

## How We Made Our CNN Stronger

### 1. Architecture Improvements
- **ResNet-style residual blocks** with skip connections
- Increased channels: 32â†’64 **became** 64â†’128â†’256
- 6 convolutional layers instead of 2

### 2. Data Augmentation
- RandomHorizontalFlip, RandomCrop
- **ColorJitter** (brightness, contrast)
- **RandomRotation** (Â±10 degrees)
- **RandomErasing** (patch dropout)

### 3. Training Techniques
- **Label Smoothing** (0.1) - prevents overconfidence
- **CosineAnnealingLR** - smooth learning rate decay
- **Early stopping** with patience=20

---

# ğŸ—ï¸ SLIDE 12: Improved CNN Architecture

## ResNet-Style Architecture

```
Input: 32Ã—32Ã—3 (RGB)
    â†“
Initial Conv(3 â†’ 64) + BatchNorm + ReLU
    â†“
Layer 1: 2Ã— ResNet Blocks (64 channels) + MaxPool â†’ 16Ã—16
    â†“
Layer 2: 2Ã— ResNet Blocks (128 channels) + Downsample â†’ 8Ã—8
    â†“
Layer 3: 2Ã— ResNet Blocks (256 channels) + Downsample â†’ 2Ã—2
    â†“
Flatten(256Ã—2Ã—2=1024) â†’ FC(256) â†’ Dropout(0.5) â†’ FC(10)
    â†“
Output: 10 class probabilities
```

### What's a Residual Block?

```
Input â”€â”€â†’ Conv â†’ BatchNorm â†’ ReLU â†’ Conv â†’ BatchNorm â”€â”€â†’ (+) â†’ ReLU â†’ Output
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†—
                    (Skip Connection)
```

**Why it works:** Gradients flow directly through skip connections!

---

# ğŸ”¥ SLIDE 13: Fun Fact - GPU Goes BRRR

## Training the Improved CNN

| Metric | Value |
|--------|-------|
| Training time | **43 minutes** |
| Epochs run | 119 (early stopped) |
| Temperature | ğŸ”¥ GPU was HOT! |

### The Training Journey:
- Epoch 1: ~45% accuracy (random guessing = 10%)
- Epoch 50: ~85% accuracy
- Epoch 99: **92.10%** accuracy (best!)
- Epoch 119: Early stopped (no improvement for 20 epochs)

---

# ğŸ‰ SLIDE 14: Improved CNN Results

## Accuracy: **92.10%** (up from 71.55%!)

| Metric | Baseline | Improved | Change |
|--------|----------|----------|--------|
| Overall accuracy | 71.55% | **92.10%** | **+20.55%** âœ… |
| Best class | 86.5% | **98.0%** | +11.5% |
| Worst class | 42.5% | **84.0%** | +41.5% |

## Per-Class Improvement:

| Class | Before | After | Î” |
|-------|--------|-------|---|
| ğŸ± cat | 42.5% | 84.0% | **+41.5%** ğŸš€ |
| ğŸ¦ bird | 54.5% | 87.5% | **+33.0%** |
| ğŸ¦Œ deer | 60.0% | 93.0% | **+33.0%** |
| ğŸš— automobile | 86.5% | 98.0% | **+11.5%** |

*[Show improved CNN confusion matrix]*

---

# ğŸ“Š SLIDE 15: Final Comparison

## CNN vs GPT-4o: The Showdown

| Aspect | Baseline CNN | Improved CNN | GPT-4o Vision |
|--------|-------------|--------------|---------------|
| **Accuracy** | 71.55% | **92.10%** | **96.75%** |
| Parameters | 1.2M | 2.3M | 1.8T |
| Training needed | Yes (50K images) | Yes (50K images) | **None** |
| Inference time | <1ms | <1ms | ~1 sec |
| Cost per image | Free | Free | ~$0.0008 |
| Total eval cost | Free | Free | ~$3 |

## The Gap:

| Comparison | Gap |
|------------|-----|
| Baseline â†’ GPT-4o | 25.2% |
| **Improved â†’ GPT-4o** | **4.65%** |
| Gap reduction | **~80%** ğŸ¯ |

---

# ğŸ“ˆ SLIDE 16: Visual Comparison

## Accuracy by Class

*[Insert bar chart comparing all 3 models across 10 classes]*

```
Class         Baseline  Improved  GPT-4o
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
airplane       78.5%     95.5%    97.5%
automobile     86.5%     98.0%    97.5%
bird           54.5%     87.5%    95.0%
cat            42.5%     84.0%    94.0%
deer           60.0%     93.0%    96.5%
dog            69.0%     86.0%    93.5%
frog           80.5%     93.5%    93.5%
horse          81.5%     93.0%    98.0%
ship           79.5%     95.5%    99.0%
truck          83.0%     95.0%    98.5%
```

---

# ğŸ” SLIDE 17: Where Models Struggle

## Common Confusion Patterns

### Cat vs Dog (The Classic Problem!)

| Model | Cat as Dog | Dog as Cat |
|-------|------------|------------|
| Baseline CNN | 56 errors | 33 errors |
| Improved CNN | 12 errors | 16 errors |
| GPT-4o | 5 errors | 6 errors |

**Why?** At 32Ã—32, cats and dogs look very similar!

*[Show example confused images]*

### Other Confusions:
- ğŸ¦ Bird â†” âœˆï¸ Airplane (both fly!)
- ğŸš— Automobile â†” ğŸš› Truck (similar shapes)
- ğŸ¦Œ Deer â†” ğŸ´ Horse (four-legged animals)

---

# ğŸ’¡ SLIDE 18: Key Findings

## What We Learned

### 1. **Zero-shot â‰  Unbeatable**
- GPT-4o wins (96.75%) but only by ~5%
- With proper techniques, CNNs can get close!

### 2. **Architecture Matters**
- ResNet blocks: +5-8% accuracy
- Skip connections enable deeper training

### 3. **Data Augmentation is Crucial**
- ColorJitter, RandomErasing: +3-5%
- Effectively multiplies training data

### 4. **Upscaling Doesn't Help GPT-4o**
- 32Ã—32 and 224Ã—224 â†’ identical 96.75%
- GPT-4o handles low-resolution well

### 5. **Trade-offs Exist**
- CNN: Free, fast, requires training
- GPT-4o: Expensive, slow, zero-shot capable

---

# ğŸš€ SLIDE 19: Conclusions

## Summary

| Achievement | Result |
|-------------|--------|
| Baseline CNN accuracy | 71.55% |
| Improved CNN accuracy | **92.10%** (+21%) |
| GPT-4o accuracy | 96.75% |
| Gap closed | From 25% â†’ **5%** |

## Main Takeaways:

1. âœ… **Custom CNNs CAN compete** with massive pre-trained models
2. âœ… **Systematic improvements work** (+21% through techniques)
3. âœ… **Trade-offs matter** (cost vs accuracy vs speed)
4. âœ… **Zero-shot is powerful** but not unbeatable

---

# ğŸ”® SLIDE 20: Future Work

## What We'd Do With More Time

### 1. Model Improvements
- Try **Vision Transformers (ViT)** instead of CNN
- Implement **attention mechanisms**
- Test **transfer learning** from ImageNet

### 2. More Experiments
- Compare with **other LLMs** (Claude, Gemini)
- Test on **harder datasets** (CIFAR-100, ImageNet)
- Evaluate **robustness** to noise/blur

### 3. Efficiency Analysis
- Measure **energy consumption**
- **Quantize** CNN for edge deployment
- Build **real-time classifier**

### 4. Interpretability
- **Grad-CAM** visualizations for CNN
- Analyze **what GPT-4o "sees"**

---

# ğŸ“š SLIDE 21: References

## Citations

1. **CIFAR-10 Dataset**
   - Krizhevsky, A. (2009). Learning Multiple Layers of Features from Tiny Images.
   - https://www.cs.toronto.edu/~kriz/cifar.html

2. **GPT-4o Vision**
   - OpenAI (2024). GPT-4o Technical Report.
   - https://platform.openai.com/docs/models/gpt-4o

3. **ResNet Architecture**
   - He, K., et al. (2016). Deep Residual Learning for Image Recognition.
   - https://arxiv.org/abs/1512.03385

4. **PyTorch Framework**
   - https://pytorch.org/

5. **Project Repository**
   - https://github.com/Sushmit404/cifar10-gpt4o-vision-test

---

# â“ SLIDE 22: Questions?

## Thank You!

### Project Links:
- ğŸ“ **GitHub**: github.com/Sushmit404/cifar10-gpt4o-vision-test
- ğŸ“Š **Results**: See `results_cnn/` and `results_gpt4o_32x32/`
- ğŸ“– **Documentation**: See `info/` folder

### Key Numbers to Remember:
| Model | Accuracy |
|-------|----------|
| Baseline CNN | 71.55% |
| Improved CNN | **92.10%** |
| GPT-4o Vision | **96.75%** |
| Gap Closed | **80%** |

*Any questions?*

---

# ğŸ“‹ APPENDIX: Speaker Notes

## Slide Distribution (8 minutes total)

| Slides | Speaker | Time |
|--------|---------|------|
| 1-4 | Either | ~1.5 min |
| 5-6 | Friend (CNN baseline) | ~1.5 min |
| 7-9 | You (GPT-4o + fun facts) | ~1.5 min |
| 10-14 | Either (improvements) | ~2 min |
| 15-20 | Either (results + conclusions) | ~1.5 min |

## Key Points to Emphasize:
1. **Open with the hook**: Can a small model beat a giant?
2. **Show the gap**: 71% vs 97% seems impossible
3. **Build the story**: We improved step by step
4. **Celebrate the win**: Closed gap by 80%!
5. **Fun facts**: Only $3 for 4,000 API calls, GPU going hot

## Things to Mention Casually:
- "Fun fact: those 4,000 API calls cost about $3... less than a coffee!"
- "The GPU was not happy during those 43 minutes of training"
- "At 32Ã—32 pixels, even WE couldn't tell cats from dogs sometimes"


